{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# From PyTorch CNN offical tutorial\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(50, 100, 3)\n",
    "        self.conv2 = nn.Conv1d(50, 100, 4)\n",
    "        self.conv3 = nn.Conv1d(50, 100, 5)\n",
    "        self.pool = nn.MaxPool1d(60)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(300, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.pool(F.relu(self.conv1(x)))\n",
    "        x2 = self.pool(F.relu(self.conv2(x)))\n",
    "        x3 = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.cat((x1, x2, x3), dim = 1).squeeze()\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_dynamic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_dynamic, self).__init__()\n",
    "        self.emb = nn.Linear(50, 50)\n",
    "        self.conv1 = nn.Conv1d(50, 100, 3)\n",
    "        self.conv2 = nn.Conv1d(50, 100, 4)\n",
    "        self.conv3 = nn.Conv1d(50, 100, 5)\n",
    "        self.pool = nn.MaxPool1d(60)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(300, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.emb(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = self.pool(F.relu(self.conv1(x)))\n",
    "        x2 = self.pool(F.relu(self.conv2(x)))\n",
    "        x3 = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.cat((x1, x2, x3), dim = 1).squeeze()\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net_2 = Net_dynamic().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_dual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_dual, self).__init__()\n",
    "        self.emb = nn.Linear(50, 50)\n",
    "        self.conv1 = nn.Conv1d(100, 100, 3)\n",
    "        self.conv2 = nn.Conv1d(100, 100, 4)\n",
    "        self.conv3 = nn.Conv1d(100, 100, 5)\n",
    "        self.pool = nn.MaxPool1d(60)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(300, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_emb = self.emb(x.transpose(1, 2)).transpose(1, 2)\n",
    "        x = torch.cat((x, x_emb), dim = 1)\n",
    "        x1 = self.pool(F.relu(self.conv1(x)))\n",
    "        x2 = self.pool(F.relu(self.conv2(x)))\n",
    "        x3 = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.cat((x1, x2, x3), dim = 1).squeeze()\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net_3 = Net_dual().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Agriculture, food and drink': 0, 'Video games': 1, 'Language and literature': 2, 'Philosophy and religion': 3, 'Social sciences and society': 4, 'Natural sciences': 5, 'Mathematics': 6, 'Engineering and technology': 7, 'Miscellaneous': 8, 'Art and architecture': 9, 'Warfare': 10, 'Geography and places': 11, 'Music': 12, 'History': 13, 'Media and drama': 14, 'Sports and recreation': 15, 'Media and darama': 14}\n",
      "['Agriculture, food and drink', 'Video games', 'Language and literature', 'Philosophy and religion', 'Social sciences and society', 'Natural sciences', 'Mathematics', 'Engineering and technology', 'Miscellaneous', 'Art and architecture', 'Warfare', 'Geography and places', 'Music', 'History', 'Media and drama', 'Sports and recreation', 'Media and darama']\n"
     ]
    }
   ],
   "source": [
    "label_train = list(set(list(np.load('D:/Courses/11747/label_train.npy'))))\n",
    "label_dict = dict()\n",
    "for idx, key in enumerate(label_train):\n",
    "    label_dict[key] = idx\n",
    "\n",
    "# add hard coding for mislabel\n",
    "label_dict['Media and darama'] = label_dict['Media and drama']\n",
    "print (label_dict)\n",
    "\n",
    "label_list = list(label_dict.keys())\n",
    "print (label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([697, 50, 60]) torch.Size([697])\n"
     ]
    }
   ],
   "source": [
    "# From PyTorch dataloader offical tutorial\n",
    "\n",
    "class Sentence():\n",
    "    \"\"\"sentence classification dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset_dir, label_dir):\n",
    "        # reshaping data from (N, length, channel) to (N, channel, length) \n",
    "        self.data = torch.from_numpy(np.load(dataset_dir)).transpose(1, 2).float().to(device)\n",
    "        \n",
    "        # reading raw label data, transform to integer value using dict         \n",
    "        label_list = np.load(label_dir)\n",
    "        self.labels = torch.zeros(self.data.shape[0]).to(device)\n",
    "        for i in range(len(self.labels)):\n",
    "            try:\n",
    "                self.labels[i] = label_dict[label_list[i]]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print (self.data.shape, self.labels.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = {'data': data, 'label': label}\n",
    "\n",
    "        return sample\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Sentence('D:/Courses/11747/data_train.npy', 'D:/Courses/11747/label_train.npy')\n",
    "dataset_val = Sentence('D:/Courses/11747/data_val.npy', 'D:/Courses/11747/label_val.npy')\n",
    "dataset_test = Sentence('D:/Courses/11747/data_test.npy', 'D:/Courses/11747/label_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=32,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=32,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=32,\n",
    "                                          shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, model_name):\n",
    "\n",
    "    model.eval()\n",
    "    err = 0\n",
    "    running_loss = 0.0\n",
    "    all_pred = []\n",
    "\n",
    "    for i, data in enumerate(val_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data['data']\n",
    "        labels = data['label'].long()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        pred = torch.argmax(outputs, dim = 1)\n",
    "        all_pred += pred.tolist()\n",
    "        err += torch.nonzero(labels - pred).size(0)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d / %d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, len(trainloader), running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculating accuracy     \n",
    "    accu = 1 - err/dataset_val.__len__()\n",
    "    print (len(all_pred))\n",
    "    print ('Accuracy: ', accu)\n",
    "    \n",
    "    # print output label txt file     \n",
    "    output_label = []\n",
    "    for pred_i in all_pred:\n",
    "        output_label.append(label_list[pred_i])\n",
    "        \n",
    "    df = pd.DataFrame(output_label)\n",
    "    df.to_csv(model_name + \"_pred.csv\", sep=',',index=False, header=False)\n",
    "    \n",
    "    return accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, model_name):\n",
    "\n",
    "    model.eval()\n",
    "    all_pred = []\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data['data']\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        pred = torch.argmax(outputs, dim = 1)\n",
    "        all_pred += pred.tolist()\n",
    "        \n",
    "    # print output label txt file     \n",
    "    output_label = []\n",
    "    for pred_i in all_pred:\n",
    "        output_label.append(label_list[pred_i])\n",
    "        \n",
    "    df = pd.DataFrame(output_label)\n",
    "    df.to_csv(model_name + \"_pred_test.csv\", sep=',',index=False, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(net, model_name, epochs = 10):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    eval_accu = []\n",
    "    train_loss = []\n",
    "    eval(net, model_name)\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['data']\n",
    "            labels = data['label'].long()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                train_loss.append(running_loss / 2000)\n",
    "                print('[%d, %5d / %d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, len(trainloader), running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        eval_accu.append(eval(net, model_name))\n",
    "        if eval_accu[-1] == max(eval_accu):\n",
    "            torch.save(net.state_dict(), model_name + '.best')\n",
    "    \n",
    "    df = pd.DataFrame(eval_accu)\n",
    "    df.to_csv(model_name + '_' + str(epochs) + \"_accu.csv\", sep=',',index=False, header=False)\n",
    "\n",
    "    df = pd.DataFrame(train_loss)\n",
    "    df.to_csv(model_name + '_' + str(epochs) + \"_train_loss.csv\", sep=',',index=False, header=False)\n",
    "\n",
    "    print('Finished Training')\n",
    "    print('Accuracy: ', eval_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n",
      "Accuracy:  0.11819595645412129\n",
      "[1,  2000 / 7935] loss: 1.834\n",
      "[1,  4000 / 7935] loss: 1.226\n",
      "[1,  6000 / 7935] loss: 1.102\n",
      "643\n",
      "Accuracy:  0.7651632970451011\n",
      "[2,  2000 / 7935] loss: 1.034\n",
      "[2,  4000 / 7935] loss: 1.001\n",
      "[2,  6000 / 7935] loss: 0.976\n",
      "643\n",
      "Accuracy:  0.7931570762052877\n",
      "[3,  2000 / 7935] loss: 0.965\n",
      "[3,  4000 / 7935] loss: 0.944\n",
      "[3,  6000 / 7935] loss: 0.927\n",
      "643\n",
      "Accuracy:  0.807153965785381\n",
      "[4,  2000 / 7935] loss: 0.927\n",
      "[4,  4000 / 7935] loss: 0.909\n",
      "[4,  6000 / 7935] loss: 0.895\n",
      "643\n",
      "Accuracy:  0.8087091757387247\n",
      "[5,  2000 / 7935] loss: 0.900\n",
      "[5,  4000 / 7935] loss: 0.884\n",
      "[5,  6000 / 7935] loss: 0.871\n",
      "643\n",
      "Accuracy:  0.8133748055987559\n",
      "[6,  2000 / 7935] loss: 0.879\n",
      "[6,  4000 / 7935] loss: 0.864\n",
      "[6,  6000 / 7935] loss: 0.852\n",
      "643\n",
      "Accuracy:  0.8195956454121307\n",
      "[7,  2000 / 7935] loss: 0.862\n",
      "[7,  4000 / 7935] loss: 0.846\n",
      "[7,  6000 / 7935] loss: 0.836\n",
      "643\n",
      "Accuracy:  0.8242612752721618\n",
      "[8,  2000 / 7935] loss: 0.847\n",
      "[8,  4000 / 7935] loss: 0.831\n",
      "[8,  6000 / 7935] loss: 0.821\n",
      "643\n",
      "Accuracy:  0.8227060653188181\n",
      "[9,  2000 / 7935] loss: 0.833\n",
      "[9,  4000 / 7935] loss: 0.818\n",
      "[9,  6000 / 7935] loss: 0.808\n",
      "643\n",
      "Accuracy:  0.8164852255054432\n",
      "[10,  2000 / 7935] loss: 0.821\n",
      "[10,  4000 / 7935] loss: 0.806\n",
      "[10,  6000 / 7935] loss: 0.796\n",
      "643\n",
      "Accuracy:  0.8195956454121307\n",
      "[11,  2000 / 7935] loss: 0.810\n",
      "[11,  4000 / 7935] loss: 0.794\n",
      "[11,  6000 / 7935] loss: 0.785\n",
      "643\n",
      "Accuracy:  0.8180404354587869\n",
      "[12,  2000 / 7935] loss: 0.799\n",
      "[12,  4000 / 7935] loss: 0.784\n",
      "[12,  6000 / 7935] loss: 0.775\n",
      "643\n",
      "Accuracy:  0.8195956454121307\n",
      "[13,  2000 / 7935] loss: 0.789\n",
      "[13,  4000 / 7935] loss: 0.774\n",
      "[13,  6000 / 7935] loss: 0.766\n",
      "643\n",
      "Accuracy:  0.8195956454121307\n",
      "[14,  2000 / 7935] loss: 0.780\n",
      "[14,  4000 / 7935] loss: 0.765\n",
      "[14,  6000 / 7935] loss: 0.757\n",
      "643\n",
      "Accuracy:  0.8149300155520995\n",
      "[15,  2000 / 7935] loss: 0.772\n",
      "[15,  4000 / 7935] loss: 0.757\n",
      "[15,  6000 / 7935] loss: 0.748\n",
      "643\n",
      "Accuracy:  0.8133748055987559\n",
      "[16,  2000 / 7935] loss: 0.763\n",
      "[16,  4000 / 7935] loss: 0.749\n",
      "[16,  6000 / 7935] loss: 0.740\n",
      "643\n",
      "Accuracy:  0.8164852255054432\n",
      "[17,  2000 / 7935] loss: 0.756\n",
      "[17,  4000 / 7935] loss: 0.741\n",
      "[17,  6000 / 7935] loss: 0.733\n",
      "643\n",
      "Accuracy:  0.8133748055987559\n",
      "[18,  2000 / 7935] loss: 0.748\n",
      "[18,  4000 / 7935] loss: 0.734\n",
      "[18,  6000 / 7935] loss: 0.726\n",
      "643\n",
      "Accuracy:  0.8118195956454122\n",
      "[19,  2000 / 7935] loss: 0.741\n",
      "[19,  4000 / 7935] loss: 0.727\n",
      "[19,  6000 / 7935] loss: 0.719\n",
      "643\n",
      "Accuracy:  0.8118195956454122\n",
      "[20,  2000 / 7935] loss: 0.734\n",
      "[20,  4000 / 7935] loss: 0.720\n",
      "[20,  6000 / 7935] loss: 0.713\n",
      "643\n",
      "Accuracy:  0.8102643856920684\n",
      "[21,  2000 / 7935] loss: 0.728\n",
      "[21,  4000 / 7935] loss: 0.714\n",
      "[21,  6000 / 7935] loss: 0.706\n",
      "643\n",
      "Accuracy:  0.8102643856920684\n",
      "[22,  2000 / 7935] loss: 0.722\n",
      "[22,  4000 / 7935] loss: 0.708\n",
      "[22,  6000 / 7935] loss: 0.701\n",
      "643\n",
      "Accuracy:  0.8102643856920684\n",
      "[23,  2000 / 7935] loss: 0.716\n",
      "[23,  4000 / 7935] loss: 0.703\n",
      "[23,  6000 / 7935] loss: 0.695\n",
      "643\n",
      "Accuracy:  0.8087091757387247\n",
      "[24,  2000 / 7935] loss: 0.710\n",
      "[24,  4000 / 7935] loss: 0.698\n",
      "[24,  6000 / 7935] loss: 0.689\n",
      "643\n",
      "Accuracy:  0.8102643856920684\n",
      "[25,  2000 / 7935] loss: 0.705\n",
      "[25,  4000 / 7935] loss: 0.693\n",
      "[25,  6000 / 7935] loss: 0.684\n",
      "643\n",
      "Accuracy:  0.807153965785381\n",
      "[26,  2000 / 7935] loss: 0.700\n",
      "[26,  4000 / 7935] loss: 0.688\n",
      "[26,  6000 / 7935] loss: 0.679\n",
      "643\n",
      "Accuracy:  0.8055987558320373\n",
      "[27,  2000 / 7935] loss: 0.695\n",
      "[27,  4000 / 7935] loss: 0.683\n",
      "[27,  6000 / 7935] loss: 0.675\n",
      "643\n",
      "Accuracy:  0.8055987558320373\n",
      "[28,  2000 / 7935] loss: 0.690\n",
      "[28,  4000 / 7935] loss: 0.678\n",
      "[28,  6000 / 7935] loss: 0.670\n",
      "643\n",
      "Accuracy:  0.7978227060653188\n",
      "[29,  2000 / 7935] loss: 0.686\n",
      "[29,  4000 / 7935] loss: 0.674\n",
      "[29,  6000 / 7935] loss: 0.666\n",
      "643\n",
      "Accuracy:  0.8009331259720063\n",
      "[30,  2000 / 7935] loss: 0.681\n",
      "[30,  4000 / 7935] loss: 0.670\n",
      "[30,  6000 / 7935] loss: 0.662\n",
      "643\n",
      "Accuracy:  0.7978227060653188\n",
      "[31,  2000 / 7935] loss: 0.677\n",
      "[31,  4000 / 7935] loss: 0.666\n",
      "[31,  6000 / 7935] loss: 0.658\n",
      "643\n",
      "Accuracy:  0.7978227060653188\n",
      "[32,  2000 / 7935] loss: 0.673\n",
      "[32,  4000 / 7935] loss: 0.662\n",
      "[32,  6000 / 7935] loss: 0.654\n",
      "643\n",
      "Accuracy:  0.7993779160186625\n",
      "[33,  2000 / 7935] loss: 0.669\n",
      "[33,  4000 / 7935] loss: 0.658\n",
      "[33,  6000 / 7935] loss: 0.650\n",
      "643\n",
      "Accuracy:  0.7947122861586314\n",
      "[34,  2000 / 7935] loss: 0.666\n",
      "[34,  4000 / 7935] loss: 0.655\n",
      "[34,  6000 / 7935] loss: 0.647\n",
      "643\n",
      "Accuracy:  0.7993779160186625\n",
      "[35,  2000 / 7935] loss: 0.662\n",
      "[35,  4000 / 7935] loss: 0.651\n",
      "[35,  6000 / 7935] loss: 0.643\n",
      "643\n",
      "Accuracy:  0.7947122861586314\n",
      "[36,  2000 / 7935] loss: 0.659\n",
      "[36,  4000 / 7935] loss: 0.648\n",
      "[36,  6000 / 7935] loss: 0.640\n",
      "643\n",
      "Accuracy:  0.7931570762052877\n",
      "[37,  2000 / 7935] loss: 0.655\n",
      "[37,  4000 / 7935] loss: 0.645\n",
      "[37,  6000 / 7935] loss: 0.637\n",
      "643\n",
      "Accuracy:  0.7900466562986003\n",
      "[38,  2000 / 7935] loss: 0.652\n",
      "[38,  4000 / 7935] loss: 0.642\n",
      "[38,  6000 / 7935] loss: 0.633\n",
      "643\n",
      "Accuracy:  0.7884914463452566\n",
      "[39,  2000 / 7935] loss: 0.649\n",
      "[39,  4000 / 7935] loss: 0.639\n",
      "[39,  6000 / 7935] loss: 0.630\n",
      "643\n",
      "Accuracy:  0.7900466562986003\n",
      "[40,  2000 / 7935] loss: 0.647\n",
      "[40,  4000 / 7935] loss: 0.636\n",
      "[40,  6000 / 7935] loss: 0.628\n",
      "643\n",
      "Accuracy:  0.7869362363919129\n",
      "[41,  2000 / 7935] loss: 0.644\n",
      "[41,  4000 / 7935] loss: 0.633\n",
      "[41,  6000 / 7935] loss: 0.625\n",
      "643\n",
      "Accuracy:  0.7884914463452566\n",
      "[42,  2000 / 7935] loss: 0.641\n",
      "[42,  4000 / 7935] loss: 0.631\n",
      "[42,  6000 / 7935] loss: 0.622\n",
      "643\n",
      "Accuracy:  0.7869362363919129\n",
      "[43,  2000 / 7935] loss: 0.638\n",
      "[43,  4000 / 7935] loss: 0.628\n",
      "[43,  6000 / 7935] loss: 0.620\n",
      "643\n",
      "Accuracy:  0.7884914463452566\n",
      "[44,  2000 / 7935] loss: 0.636\n",
      "[44,  4000 / 7935] loss: 0.626\n",
      "[44,  6000 / 7935] loss: 0.617\n",
      "643\n",
      "Accuracy:  0.7884914463452566\n",
      "[45,  2000 / 7935] loss: 0.633\n",
      "[45,  4000 / 7935] loss: 0.623\n",
      "[45,  6000 / 7935] loss: 0.614\n",
      "643\n",
      "Accuracy:  0.7869362363919129\n",
      "[46,  2000 / 7935] loss: 0.631\n",
      "[46,  4000 / 7935] loss: 0.621\n",
      "[46,  6000 / 7935] loss: 0.612\n",
      "643\n",
      "Accuracy:  0.7884914463452566\n",
      "[47,  2000 / 7935] loss: 0.628\n",
      "[47,  4000 / 7935] loss: 0.618\n",
      "[47,  6000 / 7935] loss: 0.610\n",
      "643\n",
      "Accuracy:  0.7931570762052877\n",
      "[48,  2000 / 7935] loss: 0.626\n",
      "[48,  4000 / 7935] loss: 0.616\n",
      "[48,  6000 / 7935] loss: 0.608\n",
      "643\n",
      "Accuracy:  0.7884914463452566\n",
      "[49,  2000 / 7935] loss: 0.624\n",
      "[49,  4000 / 7935] loss: 0.614\n",
      "[49,  6000 / 7935] loss: 0.605\n",
      "643\n",
      "Accuracy:  0.7869362363919129\n",
      "[50,  2000 / 7935] loss: 0.622\n",
      "[50,  4000 / 7935] loss: 0.612\n",
      "[50,  6000 / 7935] loss: 0.603\n",
      "643\n",
      "Accuracy:  0.7838258164852255\n",
      "Finished Training\n",
      "Accuracy:  [0.7651632970451011, 0.7931570762052877, 0.807153965785381, 0.8087091757387247, 0.8133748055987559, 0.8195956454121307, 0.8242612752721618, 0.8227060653188181, 0.8164852255054432, 0.8195956454121307, 0.8180404354587869, 0.8195956454121307, 0.8195956454121307, 0.8149300155520995, 0.8133748055987559, 0.8164852255054432, 0.8133748055987559, 0.8118195956454122, 0.8118195956454122, 0.8102643856920684, 0.8102643856920684, 0.8102643856920684, 0.8087091757387247, 0.8102643856920684, 0.807153965785381, 0.8055987558320373, 0.8055987558320373, 0.7978227060653188, 0.8009331259720063, 0.7978227060653188, 0.7978227060653188, 0.7993779160186625, 0.7947122861586314, 0.7993779160186625, 0.7947122861586314, 0.7931570762052877, 0.7900466562986003, 0.7884914463452566, 0.7900466562986003, 0.7869362363919129, 0.7884914463452566, 0.7869362363919129, 0.7884914463452566, 0.7884914463452566, 0.7869362363919129, 0.7884914463452566, 0.7931570762052877, 0.7884914463452566, 0.7869362363919129, 0.7838258164852255]\n"
     ]
    }
   ],
   "source": [
    "# static training: 0.7542768273716952, 0.7822706065318819, 0.8087091757387247, 0.8087091757387247, 0.8009331259720063, 0.8040435458786936, 0.807153965785381, 0.7993779160186625, 0.80248833592535, 0.8040435458786936\n",
    "# \n",
    "\n",
    "train(net, 'static', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n",
      "Accuracy:  0.055987558320373276\n",
      "[1,  2000 / 7935] loss: 1.913\n",
      "[1,  4000 / 7935] loss: 1.251\n",
      "[1,  6000 / 7935] loss: 1.106\n",
      "643\n",
      "Accuracy:  0.7589424572317263\n",
      "[2,  2000 / 7935] loss: 1.033\n",
      "[2,  4000 / 7935] loss: 1.000\n",
      "[2,  6000 / 7935] loss: 0.976\n",
      "643\n",
      "Accuracy:  0.7931570762052877\n",
      "[3,  2000 / 7935] loss: 0.968\n",
      "[3,  4000 / 7935] loss: 0.948\n",
      "[3,  6000 / 7935] loss: 0.932\n",
      "643\n",
      "Accuracy:  0.807153965785381\n",
      "[4,  2000 / 7935] loss: 0.935\n",
      "[4,  4000 / 7935] loss: 0.918\n",
      "[4,  6000 / 7935] loss: 0.905\n",
      "643\n",
      "Accuracy:  0.8087091757387247\n",
      "[5,  2000 / 7935] loss: 0.911\n",
      "[5,  4000 / 7935] loss: 0.895\n",
      "[5,  6000 / 7935] loss: 0.884\n",
      "643\n",
      "Accuracy:  0.8087091757387247\n",
      "[6,  2000 / 7935] loss: 0.892\n",
      "[6,  4000 / 7935] loss: 0.876\n",
      "[6,  6000 / 7935] loss: 0.866\n",
      "643\n",
      "Accuracy:  0.807153965785381\n",
      "[7,  2000 / 7935] loss: 0.874\n",
      "[7,  4000 / 7935] loss: 0.859\n",
      "[7,  6000 / 7935] loss: 0.850\n",
      "643\n",
      "Accuracy:  0.807153965785381\n",
      "[8,  2000 / 7935] loss: 0.859\n",
      "[8,  4000 / 7935] loss: 0.843\n",
      "[8,  6000 / 7935] loss: 0.835\n",
      "643\n",
      "Accuracy:  0.8040435458786936\n",
      "[9,  2000 / 7935] loss: 0.845\n",
      "[9,  4000 / 7935] loss: 0.829\n",
      "[9,  6000 / 7935] loss: 0.822\n",
      "643\n",
      "Accuracy:  0.8055987558320373\n",
      "[10,  2000 / 7935] loss: 0.832\n",
      "[10,  4000 / 7935] loss: 0.815\n",
      "[10,  6000 / 7935] loss: 0.808\n",
      "643\n",
      "Accuracy:  0.8040435458786936\n",
      "[11,  2000 / 7935] loss: 0.819\n",
      "[11,  4000 / 7935] loss: 0.802\n",
      "[11,  6000 / 7935] loss: 0.796\n",
      "643\n",
      "Accuracy:  0.80248833592535\n",
      "[12,  2000 / 7935] loss: 0.808\n",
      "[12,  4000 / 7935] loss: 0.791\n",
      "[12,  6000 / 7935] loss: 0.785\n",
      "643\n",
      "Accuracy:  0.7978227060653188\n",
      "[13,  2000 / 7935] loss: 0.797\n",
      "[13,  4000 / 7935] loss: 0.780\n",
      "[13,  6000 / 7935] loss: 0.774\n",
      "643\n",
      "Accuracy:  0.7993779160186625\n",
      "[14,  2000 / 7935] loss: 0.786\n",
      "[14,  4000 / 7935] loss: 0.770\n",
      "[14,  6000 / 7935] loss: 0.764\n",
      "643\n",
      "Accuracy:  0.7962674961119751\n",
      "[15,  2000 / 7935] loss: 0.776\n",
      "[15,  4000 / 7935] loss: 0.760\n",
      "[15,  6000 / 7935] loss: 0.754\n",
      "643\n",
      "Accuracy:  0.791601866251944\n",
      "[16,  2000 / 7935] loss: 0.767\n",
      "[16,  4000 / 7935] loss: 0.751\n",
      "[16,  6000 / 7935] loss: 0.745\n",
      "643\n",
      "Accuracy:  0.7931570762052877\n",
      "[17,  2000 / 7935] loss: 0.758\n",
      "[17,  4000 / 7935] loss: 0.743\n",
      "[17,  6000 / 7935] loss: 0.737\n",
      "643\n",
      "Accuracy:  0.7791601866251944\n",
      "[18,  2000 / 7935] loss: 0.750\n",
      "[18,  4000 / 7935] loss: 0.735\n",
      "[18,  6000 / 7935] loss: 0.729\n",
      "643\n",
      "Accuracy:  0.7744945567651633\n",
      "[19,  2000 / 7935] loss: 0.742\n",
      "[19,  4000 / 7935] loss: 0.727\n",
      "[19,  6000 / 7935] loss: 0.721\n",
      "643\n",
      "Accuracy:  0.776049766718507\n",
      "[20,  2000 / 7935] loss: 0.734\n",
      "[20,  4000 / 7935] loss: 0.720\n",
      "[20,  6000 / 7935] loss: 0.714\n",
      "643\n",
      "Accuracy:  0.7776049766718507\n",
      "[21,  2000 / 7935] loss: 0.727\n",
      "[21,  4000 / 7935] loss: 0.713\n",
      "[21,  6000 / 7935] loss: 0.707\n",
      "643\n",
      "Accuracy:  0.771384136858476\n",
      "[22,  2000 / 7935] loss: 0.720\n",
      "[22,  4000 / 7935] loss: 0.706\n",
      "[22,  6000 / 7935] loss: 0.700\n",
      "643\n",
      "Accuracy:  0.7682737169517885\n",
      "[23,  2000 / 7935] loss: 0.714\n",
      "[23,  4000 / 7935] loss: 0.700\n",
      "[23,  6000 / 7935] loss: 0.694\n",
      "643\n",
      "Accuracy:  0.7682737169517885\n",
      "[24,  2000 / 7935] loss: 0.708\n",
      "[24,  4000 / 7935] loss: 0.694\n",
      "[24,  6000 / 7935] loss: 0.688\n",
      "643\n",
      "Accuracy:  0.7636080870917574\n",
      "[25,  2000 / 7935] loss: 0.702\n",
      "[25,  4000 / 7935] loss: 0.688\n",
      "[25,  6000 / 7935] loss: 0.682\n",
      "643\n",
      "Accuracy:  0.7620528771384136\n",
      "[26,  2000 / 7935] loss: 0.696\n",
      "[26,  4000 / 7935] loss: 0.682\n",
      "[26,  6000 / 7935] loss: 0.677\n",
      "643\n",
      "Accuracy:  0.7620528771384136\n",
      "[27,  2000 / 7935] loss: 0.691\n",
      "[27,  4000 / 7935] loss: 0.677\n",
      "[27,  6000 / 7935] loss: 0.672\n",
      "643\n",
      "Accuracy:  0.7573872472783826\n",
      "[28,  2000 / 7935] loss: 0.686\n",
      "[28,  4000 / 7935] loss: 0.672\n",
      "[28,  6000 / 7935] loss: 0.666\n",
      "643\n",
      "Accuracy:  0.7589424572317263\n",
      "[29,  2000 / 7935] loss: 0.681\n",
      "[29,  4000 / 7935] loss: 0.667\n",
      "[29,  6000 / 7935] loss: 0.662\n",
      "643\n",
      "Accuracy:  0.7636080870917574\n",
      "[30,  2000 / 7935] loss: 0.676\n",
      "[30,  4000 / 7935] loss: 0.662\n",
      "[30,  6000 / 7935] loss: 0.657\n",
      "643\n",
      "Accuracy:  0.7589424572317263\n",
      "[31,  2000 / 7935] loss: 0.671\n",
      "[31,  4000 / 7935] loss: 0.658\n",
      "[31,  6000 / 7935] loss: 0.652\n",
      "643\n",
      "Accuracy:  0.76049766718507\n",
      "[32,  2000 / 7935] loss: 0.667\n",
      "[32,  4000 / 7935] loss: 0.653\n",
      "[32,  6000 / 7935] loss: 0.648\n",
      "643\n",
      "Accuracy:  0.7620528771384136\n",
      "[33,  2000 / 7935] loss: 0.663\n",
      "[33,  4000 / 7935] loss: 0.649\n",
      "[33,  6000 / 7935] loss: 0.644\n",
      "643\n",
      "Accuracy:  0.76049766718507\n",
      "[34,  2000 / 7935] loss: 0.658\n",
      "[34,  4000 / 7935] loss: 0.645\n",
      "[34,  6000 / 7935] loss: 0.640\n",
      "643\n",
      "Accuracy:  0.7636080870917574\n",
      "[35,  2000 / 7935] loss: 0.654\n",
      "[35,  4000 / 7935] loss: 0.641\n",
      "[35,  6000 / 7935] loss: 0.636\n",
      "643\n",
      "Accuracy:  0.7636080870917574\n",
      "[36,  2000 / 7935] loss: 0.651\n",
      "[36,  4000 / 7935] loss: 0.638\n",
      "[36,  6000 / 7935] loss: 0.632\n",
      "643\n",
      "Accuracy:  0.7651632970451011\n",
      "[37,  2000 / 7935] loss: 0.647\n",
      "[37,  4000 / 7935] loss: 0.634\n",
      "[37,  6000 / 7935] loss: 0.629\n",
      "643\n",
      "Accuracy:  0.7636080870917574\n",
      "[38,  2000 / 7935] loss: 0.644\n",
      "[38,  4000 / 7935] loss: 0.631\n",
      "[38,  6000 / 7935] loss: 0.626\n",
      "643\n",
      "Accuracy:  0.7682737169517885\n",
      "[39,  2000 / 7935] loss: 0.640\n",
      "[39,  4000 / 7935] loss: 0.627\n",
      "[39,  6000 / 7935] loss: 0.622\n",
      "643\n",
      "Accuracy:  0.7682737169517885\n",
      "[40,  2000 / 7935] loss: 0.637\n",
      "[40,  4000 / 7935] loss: 0.624\n",
      "[40,  6000 / 7935] loss: 0.619\n",
      "643\n",
      "Accuracy:  0.7682737169517885\n",
      "[41,  2000 / 7935] loss: 0.633\n",
      "[41,  4000 / 7935] loss: 0.621\n",
      "[41,  6000 / 7935] loss: 0.616\n",
      "643\n",
      "Accuracy:  0.7667185069984448\n",
      "[42,  2000 / 7935] loss: 0.631\n",
      "[42,  4000 / 7935] loss: 0.618\n",
      "[42,  6000 / 7935] loss: 0.613\n",
      "643\n",
      "Accuracy:  0.7651632970451011\n",
      "[43,  2000 / 7935] loss: 0.628\n",
      "[43,  4000 / 7935] loss: 0.615\n",
      "[43,  6000 / 7935] loss: 0.610\n",
      "643\n",
      "Accuracy:  0.76049766718507\n",
      "[44,  2000 / 7935] loss: 0.625\n",
      "[44,  4000 / 7935] loss: 0.613\n",
      "[44,  6000 / 7935] loss: 0.607\n",
      "643\n",
      "Accuracy:  0.76049766718507\n",
      "[45,  2000 / 7935] loss: 0.622\n",
      "[45,  4000 / 7935] loss: 0.610\n",
      "[45,  6000 / 7935] loss: 0.605\n",
      "643\n",
      "Accuracy:  0.76049766718507\n",
      "[46,  2000 / 7935] loss: 0.620\n",
      "[46,  4000 / 7935] loss: 0.608\n",
      "[46,  6000 / 7935] loss: 0.602\n",
      "643\n",
      "Accuracy:  0.7589424572317263\n",
      "[47,  2000 / 7935] loss: 0.617\n",
      "[47,  4000 / 7935] loss: 0.605\n",
      "[47,  6000 / 7935] loss: 0.600\n",
      "643\n",
      "Accuracy:  0.7636080870917574\n",
      "[48,  2000 / 7935] loss: 0.615\n",
      "[48,  4000 / 7935] loss: 0.603\n",
      "[48,  6000 / 7935] loss: 0.597\n",
      "643\n",
      "Accuracy:  0.7636080870917574\n",
      "[49,  2000 / 7935] loss: 0.612\n",
      "[49,  4000 / 7935] loss: 0.600\n",
      "[49,  6000 / 7935] loss: 0.595\n",
      "643\n",
      "Accuracy:  0.7682737169517885\n",
      "[50,  2000 / 7935] loss: 0.610\n",
      "[50,  4000 / 7935] loss: 0.598\n",
      "[50,  6000 / 7935] loss: 0.593\n",
      "643\n",
      "Accuracy:  0.7651632970451011\n",
      "Finished Training\n",
      "Accuracy:  [0.7589424572317263, 0.7931570762052877, 0.807153965785381, 0.8087091757387247, 0.8087091757387247, 0.807153965785381, 0.807153965785381, 0.8040435458786936, 0.8055987558320373, 0.8040435458786936, 0.80248833592535, 0.7978227060653188, 0.7993779160186625, 0.7962674961119751, 0.791601866251944, 0.7931570762052877, 0.7791601866251944, 0.7744945567651633, 0.776049766718507, 0.7776049766718507, 0.771384136858476, 0.7682737169517885, 0.7682737169517885, 0.7636080870917574, 0.7620528771384136, 0.7620528771384136, 0.7573872472783826, 0.7589424572317263, 0.7636080870917574, 0.7589424572317263, 0.76049766718507, 0.7620528771384136, 0.76049766718507, 0.7636080870917574, 0.7636080870917574, 0.7651632970451011, 0.7636080870917574, 0.7682737169517885, 0.7682737169517885, 0.7682737169517885, 0.7667185069984448, 0.7651632970451011, 0.76049766718507, 0.76049766718507, 0.76049766718507, 0.7589424572317263, 0.7636080870917574, 0.7636080870917574, 0.7682737169517885, 0.7651632970451011]\n"
     ]
    }
   ],
   "source": [
    "train(net_2, 'dynamic', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n",
      "Accuracy:  0.13219284603421466\n",
      "[1,  2000 / 7935] loss: 1.756\n",
      "[1,  4000 / 7935] loss: 1.161\n",
      "[1,  6000 / 7935] loss: 1.060\n",
      "643\n",
      "Accuracy:  0.7744945567651633\n",
      "[2,  2000 / 7935] loss: 1.002\n",
      "[2,  4000 / 7935] loss: 0.971\n",
      "[2,  6000 / 7935] loss: 0.948\n",
      "643\n",
      "Accuracy:  0.8087091757387247\n",
      "[3,  2000 / 7935] loss: 0.941\n",
      "[3,  4000 / 7935] loss: 0.919\n",
      "[3,  6000 / 7935] loss: 0.903\n",
      "643\n",
      "Accuracy:  0.8133748055987559\n",
      "[4,  2000 / 7935] loss: 0.906\n",
      "[4,  4000 / 7935] loss: 0.886\n",
      "[4,  6000 / 7935] loss: 0.873\n",
      "643\n",
      "Accuracy:  0.8164852255054432\n",
      "[5,  2000 / 7935] loss: 0.880\n",
      "[5,  4000 / 7935] loss: 0.861\n",
      "[5,  6000 / 7935] loss: 0.850\n",
      "643\n",
      "Accuracy:  0.8164852255054432\n",
      "[6,  2000 / 7935] loss: 0.858\n",
      "[6,  4000 / 7935] loss: 0.840\n",
      "[6,  6000 / 7935] loss: 0.830\n",
      "643\n",
      "Accuracy:  0.8180404354587869\n",
      "[7,  2000 / 7935] loss: 0.840\n",
      "[7,  4000 / 7935] loss: 0.822\n",
      "[7,  6000 / 7935] loss: 0.812\n",
      "643\n",
      "Accuracy:  0.8227060653188181\n",
      "[8,  2000 / 7935] loss: 0.824\n",
      "[8,  4000 / 7935] loss: 0.806\n",
      "[8,  6000 / 7935] loss: 0.797\n",
      "643\n",
      "Accuracy:  0.8227060653188181\n",
      "[9,  2000 / 7935] loss: 0.809\n",
      "[9,  4000 / 7935] loss: 0.792\n",
      "[9,  6000 / 7935] loss: 0.783\n",
      "643\n",
      "Accuracy:  0.8180404354587869\n",
      "[10,  2000 / 7935] loss: 0.796\n",
      "[10,  4000 / 7935] loss: 0.778\n",
      "[10,  6000 / 7935] loss: 0.770\n",
      "643\n",
      "Accuracy:  0.8149300155520995\n",
      "[11,  2000 / 7935] loss: 0.783\n",
      "[11,  4000 / 7935] loss: 0.766\n",
      "[11,  6000 / 7935] loss: 0.758\n",
      "643\n",
      "Accuracy:  0.8118195956454122\n",
      "[12,  2000 / 7935] loss: 0.771\n",
      "[12,  4000 / 7935] loss: 0.755\n",
      "[12,  6000 / 7935] loss: 0.747\n",
      "643\n",
      "Accuracy:  0.8149300155520995\n",
      "[13,  2000 / 7935] loss: 0.761\n",
      "[13,  4000 / 7935] loss: 0.744\n",
      "[13,  6000 / 7935] loss: 0.736\n",
      "643\n",
      "Accuracy:  0.807153965785381\n",
      "[14,  2000 / 7935] loss: 0.750\n",
      "[14,  4000 / 7935] loss: 0.734\n",
      "[14,  6000 / 7935] loss: 0.727\n",
      "643\n",
      "Accuracy:  0.8055987558320373\n",
      "[15,  2000 / 7935] loss: 0.741\n",
      "[15,  4000 / 7935] loss: 0.725\n",
      "[15,  6000 / 7935] loss: 0.717\n",
      "643\n",
      "Accuracy:  0.8055987558320373\n",
      "[16,  2000 / 7935] loss: 0.732\n",
      "[16,  4000 / 7935] loss: 0.716\n",
      "[16,  6000 / 7935] loss: 0.709\n",
      "643\n",
      "Accuracy:  0.8102643856920684\n",
      "[17,  2000 / 7935] loss: 0.723\n",
      "[17,  4000 / 7935] loss: 0.708\n",
      "[17,  6000 / 7935] loss: 0.701\n",
      "643\n",
      "Accuracy:  0.8102643856920684\n",
      "[18,  2000 / 7935] loss: 0.715\n",
      "[18,  4000 / 7935] loss: 0.700\n",
      "[18,  6000 / 7935] loss: 0.693\n",
      "643\n",
      "Accuracy:  0.807153965785381\n",
      "[19,  2000 / 7935] loss: 0.708\n",
      "[19,  4000 / 7935] loss: 0.692\n",
      "[19,  6000 / 7935] loss: 0.686\n",
      "643\n",
      "Accuracy:  0.807153965785381\n",
      "[20,  2000 / 7935] loss: 0.701\n",
      "[20,  4000 / 7935] loss: 0.685\n",
      "[20,  6000 / 7935] loss: 0.679\n",
      "643\n",
      "Accuracy:  0.80248833592535\n",
      "[21,  2000 / 7935] loss: 0.694\n",
      "[21,  4000 / 7935] loss: 0.679\n",
      "[21,  6000 / 7935] loss: 0.673\n",
      "643\n",
      "Accuracy:  0.8009331259720063\n",
      "[22,  2000 / 7935] loss: 0.688\n",
      "[22,  4000 / 7935] loss: 0.672\n",
      "[22,  6000 / 7935] loss: 0.667\n",
      "643\n",
      "Accuracy:  0.7978227060653188\n",
      "[23,  2000 / 7935] loss: 0.682\n",
      "[23,  4000 / 7935] loss: 0.667\n",
      "[23,  6000 / 7935] loss: 0.661\n",
      "643\n",
      "Accuracy:  0.7962674961119751\n",
      "[24,  2000 / 7935] loss: 0.676\n",
      "[24,  4000 / 7935] loss: 0.661\n",
      "[24,  6000 / 7935] loss: 0.656\n",
      "643\n",
      "Accuracy:  0.791601866251944\n",
      "[25,  2000 / 7935] loss: 0.671\n",
      "[25,  4000 / 7935] loss: 0.656\n",
      "[25,  6000 / 7935] loss: 0.650\n",
      "643\n",
      "Accuracy:  0.7900466562986003\n",
      "[26,  2000 / 7935] loss: 0.666\n",
      "[26,  4000 / 7935] loss: 0.651\n",
      "[26,  6000 / 7935] loss: 0.646\n",
      "643\n",
      "Accuracy:  0.791601866251944\n",
      "[27,  2000 / 7935] loss: 0.661\n",
      "[27,  4000 / 7935] loss: 0.646\n",
      "[27,  6000 / 7935] loss: 0.641\n",
      "643\n",
      "Accuracy:  0.7869362363919129\n",
      "[28,  2000 / 7935] loss: 0.656\n",
      "[28,  4000 / 7935] loss: 0.641\n",
      "[28,  6000 / 7935] loss: 0.637\n",
      "643\n",
      "Accuracy:  0.7853810264385692\n",
      "[29,  2000 / 7935] loss: 0.652\n",
      "[29,  4000 / 7935] loss: 0.637\n",
      "[29,  6000 / 7935] loss: 0.633\n",
      "643\n",
      "Accuracy:  0.7838258164852255\n",
      "[30,  2000 / 7935] loss: 0.647\n",
      "[30,  4000 / 7935] loss: 0.633\n",
      "[30,  6000 / 7935] loss: 0.629\n",
      "643\n",
      "Accuracy:  0.7807153965785381\n",
      "[31,  2000 / 7935] loss: 0.643\n",
      "[31,  4000 / 7935] loss: 0.628\n",
      "[31,  6000 / 7935] loss: 0.625\n",
      "643\n",
      "Accuracy:  0.776049766718507\n",
      "[32,  2000 / 7935] loss: 0.639\n",
      "[32,  4000 / 7935] loss: 0.624\n",
      "[32,  6000 / 7935] loss: 0.621\n",
      "643\n",
      "Accuracy:  0.7791601866251944\n",
      "[33,  2000 / 7935] loss: 0.636\n",
      "[33,  4000 / 7935] loss: 0.621\n",
      "[33,  6000 / 7935] loss: 0.618\n",
      "643\n",
      "Accuracy:  0.7776049766718507\n",
      "[34,  2000 / 7935] loss: 0.632\n",
      "[34,  4000 / 7935] loss: 0.617\n",
      "[34,  6000 / 7935] loss: 0.615\n",
      "643\n",
      "Accuracy:  0.7807153965785381\n",
      "[35,  2000 / 7935] loss: 0.629\n",
      "[35,  4000 / 7935] loss: 0.614\n",
      "[35,  6000 / 7935] loss: 0.611\n",
      "643\n",
      "Accuracy:  0.7807153965785381\n",
      "[36,  2000 / 7935] loss: 0.625\n",
      "[36,  4000 / 7935] loss: 0.610\n",
      "[36,  6000 / 7935] loss: 0.608\n",
      "643\n",
      "Accuracy:  0.7791601866251944\n",
      "[37,  2000 / 7935] loss: 0.622\n",
      "[37,  4000 / 7935] loss: 0.607\n",
      "[37,  6000 / 7935] loss: 0.605\n",
      "643\n",
      "Accuracy:  0.7822706065318819\n",
      "[38,  2000 / 7935] loss: 0.619\n",
      "[38,  4000 / 7935] loss: 0.604\n",
      "[38,  6000 / 7935] loss: 0.602\n",
      "643\n",
      "Accuracy:  0.7776049766718507\n",
      "[39,  2000 / 7935] loss: 0.616\n",
      "[39,  4000 / 7935] loss: 0.601\n",
      "[39,  6000 / 7935] loss: 0.599\n",
      "643\n",
      "Accuracy:  0.776049766718507\n",
      "[40,  2000 / 7935] loss: 0.613\n",
      "[40,  4000 / 7935] loss: 0.598\n",
      "[40,  6000 / 7935] loss: 0.596\n",
      "643\n",
      "Accuracy:  0.7776049766718507\n",
      "[41,  2000 / 7935] loss: 0.611\n",
      "[41,  4000 / 7935] loss: 0.596\n",
      "[41,  6000 / 7935] loss: 0.594\n",
      "643\n",
      "Accuracy:  0.776049766718507\n",
      "[42,  2000 / 7935] loss: 0.608\n",
      "[42,  4000 / 7935] loss: 0.593\n",
      "[42,  6000 / 7935] loss: 0.591\n",
      "643\n",
      "Accuracy:  0.7729393468118195\n",
      "[43,  2000 / 7935] loss: 0.606\n",
      "[43,  4000 / 7935] loss: 0.591\n",
      "[43,  6000 / 7935] loss: 0.589\n",
      "643\n",
      "Accuracy:  0.771384136858476\n",
      "[44,  2000 / 7935] loss: 0.603\n",
      "[44,  4000 / 7935] loss: 0.588\n",
      "[44,  6000 / 7935] loss: 0.586\n",
      "643\n",
      "Accuracy:  0.7698289269051322\n",
      "[45,  2000 / 7935] loss: 0.601\n",
      "[45,  4000 / 7935] loss: 0.586\n",
      "[45,  6000 / 7935] loss: 0.584\n",
      "643\n",
      "Accuracy:  0.7729393468118195\n",
      "[46,  2000 / 7935] loss: 0.598\n",
      "[46,  4000 / 7935] loss: 0.584\n",
      "[46,  6000 / 7935] loss: 0.582\n",
      "643\n",
      "Accuracy:  0.7744945567651633\n",
      "[47,  2000 / 7935] loss: 0.596\n",
      "[47,  4000 / 7935] loss: 0.582\n",
      "[47,  6000 / 7935] loss: 0.580\n",
      "643\n",
      "Accuracy:  0.776049766718507\n",
      "[48,  2000 / 7935] loss: 0.594\n",
      "[48,  4000 / 7935] loss: 0.580\n",
      "[48,  6000 / 7935] loss: 0.578\n",
      "643\n",
      "Accuracy:  0.7744945567651633\n",
      "[49,  2000 / 7935] loss: 0.592\n",
      "[49,  4000 / 7935] loss: 0.578\n",
      "[49,  6000 / 7935] loss: 0.576\n",
      "643\n",
      "Accuracy:  0.7744945567651633\n",
      "[50,  2000 / 7935] loss: 0.590\n",
      "[50,  4000 / 7935] loss: 0.576\n",
      "[50,  6000 / 7935] loss: 0.574\n",
      "643\n",
      "Accuracy:  0.7744945567651633\n",
      "Finished Training\n",
      "Accuracy:  [0.7744945567651633, 0.8087091757387247, 0.8133748055987559, 0.8164852255054432, 0.8164852255054432, 0.8180404354587869, 0.8227060653188181, 0.8227060653188181, 0.8180404354587869, 0.8149300155520995, 0.8118195956454122, 0.8149300155520995, 0.807153965785381, 0.8055987558320373, 0.8055987558320373, 0.8102643856920684, 0.8102643856920684, 0.807153965785381, 0.807153965785381, 0.80248833592535, 0.8009331259720063, 0.7978227060653188, 0.7962674961119751, 0.791601866251944, 0.7900466562986003, 0.791601866251944, 0.7869362363919129, 0.7853810264385692, 0.7838258164852255, 0.7807153965785381, 0.776049766718507, 0.7791601866251944, 0.7776049766718507, 0.7807153965785381, 0.7807153965785381, 0.7791601866251944, 0.7822706065318819, 0.7776049766718507, 0.776049766718507, 0.7776049766718507, 0.776049766718507, 0.7729393468118195, 0.771384136858476, 0.7698289269051322, 0.7729393468118195, 0.7744945567651633, 0.776049766718507, 0.7744945567651633, 0.7744945567651633, 0.7744945567651633]\n"
     ]
    }
   ],
   "source": [
    "train(net_3, 'dual', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(net_3, 'dual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n",
      "Accuracy:  0.8227060653188181\n"
     ]
    }
   ],
   "source": [
    "net_best = Net_dual().to(device)\n",
    "net_best.load_state_dict(torch.load('dual.best'))\n",
    "eval(net_best, 'model_best')\n",
    "test(net_best, 'model_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
